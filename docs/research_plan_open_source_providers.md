# Research Plan: Open Source LLM Providers

## Task Overview
Research comprehensive information about open source LLM providers including their API endpoints, model availability, pricing, and authentication mechanisms.

## Target Providers
- [x] Hugging Face (Inference API)
- [x] Replicate
- [x] Together AI
- [x] Groq
- [x] Reka AI
- [x] MosaicML (Databricks)
- [x] Lightning AI
- [ ] OctoML
- [x] RunPod
- [x] Lambda Labs (API deprecated)

## Research Objectives
For each provider, collect:
1. **API Endpoints**: Base URLs, specific endpoints for different operations
2. **Model Availability**: List of available open source models
3. **Pricing**: Cost per token, cost per inference, subscription plans
4. **Authentication**: API key requirements, OAuth, other auth methods
5. **Rate Limits**: Request limits, throttling policies
6. **SDK/Libraries**: Official SDKs, supported languages
7. **Special Features**: Unique capabilities, integrations

## Research Steps
1. [x] Search for official documentation and websites
2. [x] Extract detailed information from each provider's documentation
3. [x] Verify current pricing and model availability
4. [x] Document API authentication methods
5. [x] Compile findings into structured JSON format
6. [x] Save to data/llm_providers/open_source_providers.json

## Research Methods
- Web search for official documentation
- Extract content from provider websites
- Review API documentation
- Cross-verify pricing information
- Document authentication workflows

## Output Format
Structured JSON with provider details organized by categories.